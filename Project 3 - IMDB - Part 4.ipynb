{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b968472",
   "metadata": {},
   "source": [
    "# Shelly-Ann Duncan\n",
    "# 12/8/22\n",
    "# Project 3 - IMDB - Part 4\n",
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b342d1",
   "metadata": {},
   "source": [
    "* The stakeholder's first question is: does the MPAA rating of a movie (G/PG/PG-13/R) affect how much revenue the movie generates?\n",
    "\n",
    "    * They want you to perform a statistical test to get a mathematically-supported answer.\n",
    "    * They want you to report if you found a significant difference between ratings.\n",
    "        * If so, what was the p-value of you analysis?\n",
    "        * And which rating earns the most revenue?\n",
    "* They want you to prepare a visualization that supports your finding.\n",
    "\n",
    "* It is then up to you to think of 2 additional hypotheses to test that your stakeholder may want to know."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3a50a",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0f10607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json, os\n",
    "from scipy import stats\n",
    "\n",
    "import tmdbsimple as tmdb\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import create_database, database_exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01ec35e",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff539ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['API Key'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# laod API credentials\n",
    "with open('/Users/shell/.secret/tmdb_api.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "json_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ecd72df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate tmdb API variable\n",
    "tmdb.API_KEY = json_data['API Key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adafee20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' final_tmdb_data_2000.csv.gz',\n",
       " ' final_tmdb_data_2001.csv.gz',\n",
       " '.ipynb_checkpoints',\n",
       " 'combined_tmdb_data (1).csv.gz',\n",
       " 'title.akas (1).tsv.gz',\n",
       " 'title.basics.tsv.gz',\n",
       " 'title.ratings (1).tsv.gz',\n",
       " 'title_akas.csv.gz',\n",
       " 'title_akas_chunk_001.csv.gz',\n",
       " 'title_basics.csv.gz',\n",
       " 'title_basics_cleaned (1).csv.gz',\n",
       " 'title_ratings.csv.gz',\n",
       " 'tmdb_api_results_2000.json',\n",
       " 'tmdb_api_results_2001.json',\n",
       " 'tmdb_results_combined.csv.gz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify folder for saving data\n",
    "FOLDER = 'Data/'\n",
    "os.makedirs(FOLDER, exist_ok = True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba46f0a3",
   "metadata": {},
   "source": [
    "### Extract revenue and certification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd3d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get movie with certification included\n",
    "\n",
    "def get_movie_with_rating(movie_id):\n",
    "    \"\"\"Adapted from source = https://github.com/celioa/tmdbsimple\"\"\"\n",
    "    # get the movie object for the current id\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    \n",
    "    # save the .info .releases dictionaries\n",
    "    info = movie.info()\n",
    "    \n",
    "    releases = movie.releases()\n",
    "    \n",
    "    # loop through coountries in releases\n",
    "    for c in releases['countries']:\n",
    "       \n",
    "        # if the country abbreviation==US\n",
    "        if c['iso_3166_1'] == 'US':\n",
    "            \n",
    "            # save a \"certification\" key in info with the certification \n",
    "            info['certification'] = c['certification']\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52aee94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to load/write the new json files\n",
    "\n",
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        \n",
    "        # Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        \n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        \n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d40b47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0035423</td>\n",
       "      <td>movie</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>Comedy,Fantasy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0062336</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Tango of the Widower and Its Distorting Mi...</td>\n",
       "      <td>El Tango del Viudo y Su Espejo Deformante</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0069049</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0088751</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Naked Monster</td>\n",
       "      <td>The Naked Monster</td>\n",
       "      <td>0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>Comedy,Horror,Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0093119</td>\n",
       "      <td>movie</td>\n",
       "      <td>Grizzly II: Revenge</td>\n",
       "      <td>Grizzly II: The Predator</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>Horror,Music,Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst titleType                                       primaryTitle  \\\n",
       "0  tt0035423     movie                                     Kate & Leopold   \n",
       "1  tt0062336     movie  The Tango of the Widower and Its Distorting Mi...   \n",
       "2  tt0069049     movie                         The Other Side of the Wind   \n",
       "3  tt0088751     movie                                  The Naked Monster   \n",
       "4  tt0093119     movie                                Grizzly II: Revenge   \n",
       "\n",
       "                               originalTitle  isAdult  startYear  endYear  \\\n",
       "0                             Kate & Leopold        0     2001.0      NaN   \n",
       "1  El Tango del Viudo y Su Espejo Deformante        0     2020.0      NaN   \n",
       "2                 The Other Side of the Wind        0     2018.0      NaN   \n",
       "3                          The Naked Monster        0     2005.0      NaN   \n",
       "4                   Grizzly II: The Predator        0     2020.0      NaN   \n",
       "\n",
       "   runtimeMinutes                  genres  \n",
       "0             118  Comedy,Fantasy,Romance  \n",
       "1              70                   Drama  \n",
       "2             122                   Drama  \n",
       "3             100    Comedy,Horror,Sci-Fi  \n",
       "4              74   Horror,Music,Thriller  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load basics dataset from part 1\n",
    "basics = pd.read_csv('Data/title_basics_cleaned (1).csv.gz')\n",
    "basics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f41c4dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 year range of data needed\n",
    "YEARS_TO_GET = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf632c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebb3bb3839a49a180f1eb2083e289ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YEARS:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d3cb24b6cf4102b220d3d272076f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2010:   0%|          | 0/3749 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# Finally, store our info in the JSON_FILE\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m final_year_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJSON_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m final_year_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m final_tmdb_data_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mYEAR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     58\u001b[0m                      compression \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m'\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\util\\_decorators.py:207\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:612\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m json_reader:\n\u001b[1;32m--> 612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:746\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    744\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_lines(data_lines))\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:768\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    766\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 768\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:880\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_numpy()\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 880\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_no_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    883\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:1133\u001b[0m, in \u001b[0;36mFrameParser._parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1129\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[1;32m-> 1133\u001b[0m         \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m     )\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1136\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1139\u001b[0m     }\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# create a for loop to filter through the years\n",
    "# Outer loop\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc = 'YEARS', position = 0):\n",
    "    \n",
    "    # Define the JSON file to store results for years\n",
    "    # This will show at the beginng \n",
    "    JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "    \n",
    "    # Check to see if our file exists\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "    \n",
    "    # Now, create the file if it exists, or leave it if it does exist\n",
    "    if file_exists == False:\n",
    "    \n",
    "        # Save an empty dict to a new json file to append later\n",
    "        with open(JSON_FILE, 'w') as f:\n",
    "            json.dump([{'imdb_id':0}],f)\n",
    "        \n",
    "    # Now, save our specifisc years as the current df YEAR = 2010\n",
    "    df = basics.loc[basics['startYear'] == YEAR].copy()\n",
    "    df.head()\n",
    "\n",
    "    # Save movie ids from the year 2010 to a list\n",
    "    movie_ids = df['tconst'].copy()\n",
    "    movie_ids\n",
    "\n",
    "    # Check for any previous data\n",
    "    previous_df = pd.read_json(JSON_FILE)\n",
    "    previous_df # will be empty at first\n",
    "    \n",
    "    # Filter out any ids that already exist in our JSON_FILE (helps when returning to our problem later)\n",
    "    movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "    \n",
    "# Get index and movie id from list\n",
    "# Inner loop\n",
    "\n",
    "    for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                      desc = f'Movies from {YEAR}',\n",
    "                                      position = 1,\n",
    "                                      leave = True):\n",
    "            # Make attempt to retrieve data for movie id\n",
    "        try:\n",
    "            temp = get_movie_with_rating(movie_id) # Our first function\n",
    "\n",
    "                # Extend results of our file with our other function\n",
    "                \n",
    "            write_json(temp, JSON_FILE)\n",
    "\n",
    "                # Create a short sleep (helps bog down the server less)\n",
    "            time.sleep(0.02)\n",
    "\n",
    "            # If it fails, make a dict with just the id\n",
    "        except Exception as e:\n",
    "            continue\n",
    "            \n",
    "        # Finally, store our info in the JSON_FILE\n",
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER} final_tmdb_data_{YEAR}.csv.gz\",\n",
    "                         compression = 'gzip', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
